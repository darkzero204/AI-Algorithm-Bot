# Data manipulation and mathematical libraries
import numpy as np
import pandas as pd
from datetime import timedelta
import pandas_datareader as pdr

# Machine learning and deep learning libraries
import tensorflow as tf
from tensorflow.keras.layers import GRU, Dense, Dropout, Input, LSTM, Conv1D, Flatten, concatenate
from tensorflow.keras.models import Sequential
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from tensorforce.agents import PPOAgent
from tensorforce.environments import Environment

# Technical indicators and cryptocurrency exchange libraries
import talib
import ccxt

# Social media and news data libraries
import tweepy
from newsapi import NewsApiClient

# Economic data library
from fredapi import Fred

# Hyperparameter tuning libraries
from kerastuner.tuners import RandomSearch
from skopt import BayesSearchCV, gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args

# Risk management libraries
import pyfolio as pf
from pyfolio import timeseries
from pypfopt import EfficientFrontier, objective_functions
from pypfopt import risk_models, expected_returns
from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices

# Create some sample data
n_samples = 1000
n_features = 10
X = np.random.rand(n_samples, n_features)
y = np.random.rand(n_samples)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def build_model(observation_shape, action_shape):
    observation_input = Input(shape=(observation_shape,))
    x = LSTM(64, activation='relu')(observation_input)

    conv_input = Input(shape=(observation_shape, 1))
    y = Conv1D(64, 3, activation='relu')(conv_input)
    y = Flatten()(y)

    combined = concatenate([x, y])
    z = Dense(64, activation='relu')(combined)
    output = Dense(action_shape, activation='softmax')(z)

    model = Model(inputs=[observation_input, conv_input], outputs=output)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    return model

def train_agent(env, model):
    agent = PPOAgent(
        states=env.states(),
        actions=env.actions(),
        network=model,
        update_mode=dict(batch_size=32, frequency=4),
        memory=dict(type='replay', capacity=5000),
        optimizer=dict(type='adam', learning_rate=1e-4),
        discount=0.99,
        entropy_regularization=0.01,
        baseline_mode='states',
        baseline=dict(type='mlp', sizes=[64, 64]),
        max_episode_timesteps=env.max_episode_timesteps(),
        saver=dict(directory='models', filename='ppo')
    )

    for _ in range(100):
        states = env.reset()
        terminal = False

        while not terminal:
            actions = agent.act(states=states)
            states, reward, terminal = env.execute(actions=actions)
            agent.observe(reward=reward, terminal=terminal)

        print(f'Episode reward: {reward}')

    return agent
# LSTM model
def create_lstm_model():
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=(n_features, 1)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

lstm_model = KerasRegressor(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)

# CNN model
def create_cnn_model():
    model = Sequential()
    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_features, 1)))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(50, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

cnn_model = KerasRegressor(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)

# XGBoost model
xgb_model = XGBRegressor(objective='reg:squarederror', n_jobs=-1)

# Bayesian optimization
opt = BayesSearchCV(
    estimator=xgb_model,
    search_spaces={
        'learning_rate': (0.01, 1.0, 'log-uniform'),
        'n_estimators': (50, 100),
        'max_depth': (1, 50),
        'min_child_weight': (1, 10),
        'gamma': (0, 1, 'uniform'),
        'subsample': (0.1, 1, 'uniform'),
        'colsample_bytree': (0.1, 1, 'uniform'),
    },
    n_iter=50,
    cv=3,
    verbose=1
)

# Reshape data for LSTM and CNN
X_train_lstm_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_lstm_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Fit models
lstm_model.fit(X_train_lstm_cnn, y_train)
cnn_model.fit(X_train_lstm_cnn, y_train)
opt.fit(X_train, y_train)

# Ensemble predictions
lstm_pred = lstm_model.predict(X_test_lstm_cnn)
cnn_pred = cnn_model.predict(X_test_lstm_cnn)
xgb_pred = opt.predict(X_test)

ensemble_pred = (lstm_pred + cnn_pred + xgb_pred) / 3

# Calculate the mean squared error
mse = mean_squared_error
def create_sequences(data, seq_length):
    x = []
    y = []

    for i in range(len(data) - seq_length - 1):
        x.append(data[i : (i + seq_length)])
        y.append(data[i + seq_length])

    return np.array(x), np.array(y)

# Load and preprocess data
data = pd.read_csv('AAPL.csv')
prices = data['Close'].values.reshape(-1, 1)

# Scale input data
scaler = MinMaxScaler(feature_range=(0, 1))
prices = scaler.fit_transform(prices)

# Create input sequences
seq_length = 30
x, y = create_sequences(prices, seq_length)

# Split the data
train_size = int(len(prices) * 0.8)
x_train, x_test = x[:train_size], x[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Define a function for model creation, used by Keras Tuner
def build_model(hp):
    model = Sequential()
    model.add(GRU(units=hp.Int("gru_units", min_value=32, max_value=128, step=32),
                  activation="tanh",
                  input_shape=(seq_length, 1),
                  return_sequences=True))
    model.add(Dropout(hp.Float("dropout_rate", min_value=0.1, max_value=0.5, step=0.1)))
    model.add(GRU(units=hp.Int("gru_units", min_value=32, max_value=128, step=32),
                  activation="tanh"))
    model.add(Dropout(hp.Float("dropout_rate", min_value=0.1, max_value=0.5, step=0.1)))
    model.add(Dense(1))

    model.compile(loss="mean_squared_error",
                  optimizer=tf.keras.optimizers.Adam(
                      hp.Choice("learning_rate", values=[1e-2, 1e-3, 1e-4])))
    
    return model
# Configure Keras Tuner
tuner = RandomSearch(build_model,
                     objective="val_loss",
                     max_trials=30,
                     directory="keras_tuner",
                     project_name="stock_price_prediction")

# Search for the best hyperparameters
tuner.search(x_train, y_train,
             epochs=20,
             batch_size=64,
             validation_data=(x_test, y_test))

# Get the best model
best_model = tuner.get_best_models(num_models=1)[0]

# Train the best model
history = best_model.fit(x_train, y_train,
                         epochs=100,
                         batch_size=64,
                         validation_data=(x_test, y_test))

# Evaluate the model
mse = best_model.evaluate(x_test, y_test)
print("Test MSE:", mse)
class MyCryptoAlgorithm(QCAlgorithm):

    api_key = 'XHj9kgf3gf43f423own7'
    api_secret = 'zFpKW1xxxxxxxVyRaoRhkI'
    api_passphrase = '!,Mxxxxxxyw'

    exchange = ccxt.coinbasepro({
        'apiKey': api_key,
        'secret': api_secret,
        'password': api_passphrase,
        'rateLimit': 1000,
    })

class MyAlgorithm(QCAlgorithm):

    def Initialize(self):
        self.SetStartDate(2023, 4, 10)
        self.SetEndDate(2024, 4, 20)
        self.SetCash(500)
        self.SetWarmUp(20)
        self.coins = ['BTC-USD', 'ETH-USD', 'LTC-USD', 'BCH-USD', 'LRC-USD', 'CRO-USD']
        self.exchange = 'Coinbase'
        self.position_size_multiplier = 0.20
        self.trailing_stop_loss_pct = 0.05
        self.Schedule.On(self.DateRules.EveryDay(), self.TimeRules.At(9, 30), self.PlotIndicator)
        self.Schedule.On(self.DateRules.EveryDay(), self.TimeRules.At(9, 30), self.PlaceOrders)
        self.symbol_mapper = CoinbaseSymbolMapper()
        self.symbols = {}
        self.trailing_stop_loss_orders = {}
        self.sentiment_pipeline = pipeline('sentiment-analysis')
        #self.twitter = Twitter(twitter_api_key, twitter_api_secret, twitter_access_token, twitter_access_token_secret)
        for coin in self.coins:
            self.AddCrypto(coin)
            self.trailing_stop_loss_orders[coin] = None

    def AddCrypto(self, coin):
        symbol = self.symbol_mapper.GetLeanSymbol(coin, SecurityType.Crypto, Market.Coinbase)
        security = self.AddSecurity(SecurityType.Crypto, symbol, Resolution.Hour, Market.Coinbase, True, 1, True)
        security.SetDataNormalizationMode(DataNormalizationMode.Raw)
        self.symbols[coin] = security

    # Add sentiment analysis methods
    def calculate_sentiment_score(self, text):
        sentiment = self.sentiment_pipeline(text)[0]
        if sentiment['label'] == 'POSITIVE':
            sentiment_score = sentiment['score']
        else:  # 'NEGATIVE'
            sentiment_score = -sentiment['score']

        return sentiment_score
        for word in words:
            if word in positive_keywords:
                sentiment_score += 1
            elif word in negative_keywords:
                sentiment_score -= 1

        return sentiment_score

    def get_coin_sentiment(self, coin, text_data):
        sentiment_scores = [self.calculate_sentiment_score(text) for text in text_data]
        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
        return avg_sentiment_score
def TrainModel(self, coin):
    # Fetch historical prices
    symbol = self.symbol_mapper.GetLeanSymbol(coin, SecurityType.Crypto, Market.Coinbase)
    history = self.History(symbol, TimeSpan.FromDays(365), Resolution.Daily).close
    prices = [float(x) for x in history]

    # Create the training data
    x_train = prices[:-1]
    y_train = prices[1:]

    # Define the neural network
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(units=1, input_shape=[1])
    ])

    # Compile the model
    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))

    # Train the model
    model.fit(x_train, y_train, epochs=100)

    # Predict the next price
    next_price = model.predict([prices[-1]])

    self.Log(f"Next price for {coin}: {next_price[0][0]}")

    def PlotIndicator(self):
        for coin in self.coins:
            symbol = self.symbol_mapper.GetLeanSymbol(coin, SecurityType.Crypto, Market.Coinbase)
        security = self.Securities[symbol]
        history = self.History(symbol, 90, Resolution.Daily)

        if not history.empty:
            close = history.loc[symbol.Value]['close']
            upper_band, middle_band, lower_band = talib.BBANDS(close, timeperiod=20)
            self.Plot('BollingerBands', f'{coin}-UpperBand', upper_band[-1])
            self.Plot('BollingerBands', f'{coin}-MiddleBand', middle_band[-1])
            self.Plot('BollingerBands', f'{coin}-LowerBand', lower_band[-1])

            # Calculate and plot RSI
            rsi = talib.RSI(close, timeperiod=14)
            self.Plot('RSI', f'{coin}-RSI', rsi[-1])

            # Ichimoku Cloud
            tenkan_sen = (talib.MAX(history.loc[symbol.Value]['high'].tail(9)) + talib.MIN(history.loc[symbol.Value]['low'].tail(9))) / 2
            kijun_sen = (talib.MAX(history.loc[symbol.Value]['high'].tail(26)) + talib.MIN(history.loc[symbol.Value]['low'].tail(26))) / 2
            senkou_span_a = (tenkan_sen + kijun_sen) / 2
            senkou_span_b = (talib.MAX(history.loc[symbol.Value]['high'].tail(52)) + talib.MIN(history.loc[symbol.Value]['low'].tail(52))) / 2
            self.Plot('IchimokuCloud', f'{coin}-TenkanSen', tenkan_sen[-1])
            self.Plot('IchimokuCloud', f'{coin}-KijunSen', kijun_sen[-1])
            self.Plot('IchimokuCloud', f'{coin}-SenkouSpanA', senkou_span_a.shift(26)[-1])
            self.Plot('IchimokuCloud', f'{coin}-SenkouSpanB', senkou_span_b.shift(26)[-1])

            # MACD
            macd, signal, hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
            self.Plot('MACD', f'{coin}-MACD', macd[-1])
            self.Plot('MACD', f'{coin}-Signal', signal[-1])

            # Stochastic Oscillator
            high = history.loc[symbol.Value]['high']
            low = history.loc[symbol.Value]['low']
            slowk, slowd = talib.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)
            self.Plot('StochasticOscillator', f'{coin}-SlowK', slowk[-1])
            self.Plot('StochasticOscillator', f'{coin}-SlowD', slowd[-1])
    # Modify the CalculatePositionSizes method
    def CalculatePositionSizes(self, current_prices, sentiment_scores):
        total_value = sum([current_prices[coin] * self.Portfolio[coin].Quantity for coin in self.coins])

        # Calculate the adjusted position sizes based on sentiment scores
        total_sentiment = sum([abs(sentiment_scores[coin]) for coin in self.coins])
        position_sizes = {
            coin: (self.position_size_multiplier * total_value * abs(sentiment_scores[coin]) / total_sentiment) / current_prices[coin]
            for coin in self.coins
        }

        return position_sizes
    def PlaceOrders(self):
        current_prices = {coin: self.Securities[self.symbols[coin]].Price for coin in self.coins}

        # Replace this line with your code to fetch text data for each coin
        coin_text_data = {coin: [] for coin in self.coins}

        sentiment_scores = {coin: self.get_coin_sentiment(coin, coin_text_data[coin]) for coin in self.coins}

        # Adjust position sizes based on sentiment scores
        position_sizes = self.CalculatePositionSizes(current_prices, sentiment_scores)

        for coin in self.coins:
            symbol = self.symbols[coin]
            price = current_prices[coin]
            quantity = position_sizes[coin] / price
            security = self.Securities[symbol]

            if security.Invested:
                if self.trailing_stop_loss_orders[coin] is not None:
                    current_price = security.Price
                    if self.trailing_stop_loss_orders[coin].StopPrice < current_price * (1 - self.trailing_stop_loss_pct):
                        new_stop_price = current_price * (1 - self.trailing_stop_loss_pct)
                        self.trailing_stop_loss_orders[coin].Update(new_stop_price)
                        self.Log(f'Adjusting trailing stop loss order for {coin}: New stop price = {new_stop_price}')
                elif security.Holdings.UnrealizedProfitPercent < 0:
                    stop_price = security.Price * (1 - self.trailing_stop_loss_pct)
                    quantity = security.Holdings.Quantity
                    trailing_stop_loss_order = self.StopMarketOrder(symbol, -quantity, stop_price)
                    self.trailing_stop_loss_orders[coin] = trailing_stop_loss_order
                    self.Log(f'Placed trailing stop loss order for {coin}: Stop price = {stop_price}')
            elif quantity > 0:
                self.SetHoldings(symbol, quantity)
                self.Log(f'Setting holdings for {coin}: Quantity = {quantity}')
def OnData(self, data):
    for coin in self.coins:
        news_articles = self.news.get_articles(coin)
        coin_text_data = news_articles  # + tweets
        # tweets = self.twitter.get_tweets(coin)
        # Combine news_articles and tweets
        symbol = self.symbol_mapper.GetLeanSymbol(coin, SecurityType.Crypto, Market.Coinbase)
        sentiment_scores[coin] = self.get_coin_sentiment(coin, coin_text_data)
        security = self.Securities[symbol]

        if not security.Invested:
            continue
        
        # Check if we need to adjust the trailing stop loss order
        if self.trailing_stop_loss_orders[coin] is not None:
            current_price = security.Price
            if self.trailing_stop_loss_orders[coin].StopPrice < current_price * (1 - self.trailing_stop_loss_pct):
                # Move the stop price down to the new trailing stop loss level
                new_stop_price = current_price * (1 - self.trailing_stop_loss_pct)
                self.trailing_stop_loss_orders[coin].Update(new_stop_price)
                self.Log(f'Adjusting trailing stop loss order for {coin}: New stop price = {new_stop_price}')

        # Check if we need to place a trailing stop loss order
        if security.Holdings.UnrealizedProfitPercent < 0 and self.trailing_stop_loss_orders[coin] is None:
            # Place a trailing stop loss order
            stop_price = security.Price * (1 - self.trailing_stop_loss_pct)
            quantity = security.Holdings.Quantity
            trailing_stop_loss_order = self.StopMarketOrder(symbol, -quantity, stop_price)
            self.trailing_stop_loss_orders[coin] = trailing_stop_loss_order
            self.Log(f'Placed trailing stop loss order for {coin}: Stop price = {stop_price}')
    # Add method to fetch news articles
    def fetch_news(self, coin):
        # Set up the NewsAPI client and fetch news articles
        news_articles = self.news_api.get_everything(q=coin, from_param=self.Time - timedelta(days=1), to=self.Time)
        news_headlines = [article['title'] for article in news_articles['articles']]
        return news_headlines
    # Add method to fetch social media posts
    def fetch_social_media(self, coin):
        # Set up the Twitter API client and fetch tweets
        tweets = self.twitter_api.search(q=coin, count=100)
        tweet_texts = [tweet.text for tweet in tweets]
        return tweet_texts
    # Add method to fetch macroeconomic data
    def fetch_macro_data(self):
        # Fetch macroeconomic data from FRED
        gdp = self.fred_api
class News:
    def __init__(self, api_key):
        self.api_key = api_key

    def get_articles(self, coin):
        url = f"https://newsapi.org/v2/everything?q={coin}&from=2023-04-10&to=2024-04-20&sortBy=popularity&apiKey={self.api_key}"
        response = requests.get(url)
        articles = response.json()["articles"]
        return [article["title"] for article in articles]
# class Twitter:
#     def __init__(self, api_key, api_secret_key, access_token, access_token_secret):
#         self.auth = tweepy.OAuthHandler(api_key, api_secret_key)
#         self.auth.set_access_token(access_token, access_token_secret)
#         self.api = tweepy.API(self.auth)
#
#     def get_tweets(self, coin):
#         tweets = self.api.search(q=coin, lang="en", tweet_mode="extended", count=100)
#         return [tweet.full_text for tweet in tweets]
class MacroData:
    def __init__(self):
        self.fred = Fred(api_key="your_api_key_here")

    def get_macro_data(self):
        gdp = self.fred.get_series("GDP")
        unemployment = self.fred.get_series("UNRATE")
        inflation = self.fred.get_series("CPALTT01USM657N")
        return gdp, unemployment, inflation
def objective_function(params):
    # Unpack the parameters
    param1, param2, param3 = params
    
    # Evaluate your trading strategy using these parameters
    # (replace this function with your backtesting code)
    performance = evaluate_trading_strategy(param1, param2, param3)
    
    # Since we want to maximize the performance, return the negative value
    return -performance

# Define the search space for your parameters
search_space = [
    Real(0.01, 0.5, name='param1'),
    Integer(10, 100, name='param2'),
    Real(0.001, 0.1, name='param3')
]

# Use named arguments to unpack the parameters in the objective function
@use_named_args(search_space)
def evaluate_trading_strategy(param1, param2, param3):
    # Your backtesting code using param1, param2, and param3
    # (replace this with your actual backtesting code)
    performance = np.random.random()  # Dummy performance value
    return performance

# Run Bayesian optimization
result = gp_minimize(evaluate_trading_strategy, search_space, n_calls=50, n_random_starts=10, random_state=42)

# Extract the best parameters
best_parameters = result.x

# Print the best parameters
print(f"Best parameters: {best_parameters}")
class TradingEnvironment(Environment):
    def __init__(self, data):
        self.data = data
        self.action_space = 2  # Buy or Sell
        self.observation_space = data.shape[1]
        self.current_step = 0

    def states(self):
        return dict(type='float', shape=(self.observation_space,))

    def actions(self):
        return dict(type='int', num_actions=self.action_space)

    def max_episode_timesteps(self):
        return len(self.data) - 1

    def reset(self):
        self.current_step = 0
        return self.data.iloc[self.current_step]

    def execute(self, actions):
        reward = 0
        done = False

        if actions == 0:
            # Buy
            if self.current_step < len(self.data) - 1:
                reward = self.data.iloc[self.current_step + 1]['Close'] - self.data.iloc[self.current_step]['Close']
                self.current_step += 1
            else:
                done = True
        elif actions == 1:
            # Sell
            if self.current_step < len(self.data) - 1:
                reward = self.data.iloc[self.current_step]['Close'] - self.data.iloc[self.current_step + 1]['Close']
                self.current_step += 1
            else:
                done = True

        if done:
            return None, reward, done
        else:
            return self.data.iloc[self.current_step], reward, done
